# Sentinel ğŸ›¡ï¸

**ML Data Quality Gate** - Detects corrupted images before they corrupt your models.

## What is Sentinel?

Sentinel is a production-ready CLI tool that sits between data ingestion and model training in ML pipelines. It automatically flags corrupted, blurred, or degraded images that would hurt model performance.

### Key Features

- **Fast**: <50ms per image on T4 GPU
- **Interpretable**: Spatial alpha maps show exactly WHERE corruption is detected
- **No Fine-Tuning**: Works on any image resolution without retraining
- **Production-Ready**: Drop-in filter for ML pipelines

## How It Works

```
Data Ingestion â†’ [SENTINEL] â†’ Clean Data â†’ Model Training
                      â†“
                  Flagged samples
                  + Alpha heatmaps
```

Sentinel uses:
1. **UNet** - Learns clean image reconstruction
2. **Spatial Alpha Controller** (our innovation) - Predicts per-pixel corruption likelihood
3. **Alpha Maps** - Visual heatmaps showing where corruption was detected

## Installation

```bash
# Clone the repo
git clone https://github.com/kelsierlol/sentinel.git
cd sentinel

# Install dependencies
pip install typer rich

# Install sentinel in development mode
pip install -e .
```

## Quick Start

```bash
# Check images for corruption
sentinel check ./my_images/ --threshold 0.05

# Train on your clean data (optional domain adaptation)
sentinel train ./clean_training_data/ --epochs-unet 50 --epochs-alpha 30

# Run benchmarks
sentinel benchmark --imagenet-c /path/to/imagenet-c/

# Show version
sentinel version
```

## CLI Commands

### `sentinel check`
Run quality gate on a batch of images.

```bash
sentinel check \
  --input /data/incoming/ \
  --output results.json \
  --threshold 0.05 \
  --device cuda
```

**Output**:
```json
{
  "summary": {
    "total": 1000,
    "passed": 953,
    "flagged": 47,
    "flag_rate": 0.047
  },
  "flagged_samples": [
    {"path": "img_042.jpg", "score": 0.089},
    {"path": "img_103.jpg", "score": 0.072}
  ]
}
```

### `sentinel train`
Train or adapt sentinel to your domain.

```bash
sentinel train \
  ./clean_data/ \
  --epochs-unet 50 \
  --epochs-alpha 30 \
  --output-dir ./weights/
```

### `sentinel benchmark`
Run ImageNet-C benchmarks.

```bash
sentinel benchmark \
  --imagenet-c /path/to/imagenet-c/ \
  --imagenet-val /path/to/val/
```

## Architecture

### Fixed Alpha Controller (Our Innovation)

Previous approach (broken): 1x1 convolutions â†’ **no spatial context** â†’ can't detect spatial corruptions

**Our fix**: 3x3 spatial convolutions â†’ 7x7 receptive field â†’ catches blur, occlusion, artifacts

```python
from sentinel import SpatialAlphaController

# The fixed architecture
alpha_controller = SpatialAlphaController(
    in_channels=2,          # resid_mag + redundancy
    hidden_channels=32,     # Capacity
    num_layers=3,          # 7x7 receptive field
)
```

## Validation Metrics

We validate against 4 production-grade metrics:

1. **ImageNet-C Benchmark**: AUROC/F1 across 15 corruption types
   - Target: Beat OpenCV baselines by 10-15%

2. **<5% FPR on Clean Data**: Run on 10k ImageNet val images
   - Target: Flag <500 images (5% false positive rate)

3. **Speed**: <50ms/image on T4 GPU at batch_size=32

4. **Real Pilot**: >80% human agreement on flagged samples

## Development Status

ğŸš§ **Phase 1 (Current)**: Core architecture implemented
- âœ… SpatialAlphaController with 3x3 convs
- âœ… UNet reconstruction model
- âœ… QualityGate engine
- âœ… CLI skeleton
- â³ Testing on CIFAR-10

ğŸ“‹ **Phase 2**: ImageNet-C benchmarking
ğŸ“‹ **Phase 3**: Full CLI implementation
ğŸ“‹ **Phase 4**: Production hardening
ğŸ“‹ **Phase 5**: Validation & pilot deployment

## Why Sentinel vs Alternatives?

| Feature | Sentinel | PatchCore | OpenCV |
|---------|----------|-----------|---------|
| Speed | **<50ms** | 100-200ms | <10ms |
| Interpretability | **âœ… Heatmaps** | âŒ Opaque | âŒ Threshold |
| Generalization | **âœ… Any resolution** | âŒ Needs tuning | âš ï¸ Per-corruption |
| Accuracy | **Target: 0.80+ PR-AUC** | 0.98 (slow) | 0.54 |

**The sweet spot**: Fast enough for production, accurate enough to prevent model degradation, interpretable enough for human review.

## License

MIT

## Citation

```bibtex
@software{sentinel2026,
  title = {Sentinel: ML Data Quality Gate},
  author = {Prajwal},
  year = {2026},
  url = {https://github.com/kelsierlol/sentinel}
}
```

## Roadmap

- [ ] Phase 1: Validate on CIFAR-10 (PR-AUC >= 0.80)
- [ ] Phase 2: ImageNet-C benchmark
- [ ] Phase 3: Full CLI with check/train/calibrate
- [ ] Phase 4: Drift detection & observability
- [ ] Phase 5: First pilot deployment
- [ ] Phase 6: PyPI release

---

**Built with spatial alpha maps** ğŸ—ºï¸ | **Made for production ML** ğŸš€
