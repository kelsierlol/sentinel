{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel Phase 2: ImageNet-C Benchmark\n",
    "\n",
    "This notebook benchmarks Sentinel against OpenCV baselines on ImageNet-C corruptions.\n",
    "\n",
    "**Hardware Requirements:** GPU (T4 or better)\n",
    "\n",
    "**Runtime:** ~30-45 minutes for 3 corruption types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Sentinel repo\n",
    "!git clone https://github.com/kelsierlol/sentinel.git\n",
    "%cd sentinel\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -e . -q\n",
    "!pip install opencv-python matplotlib -q\n",
    "\n",
    "print(\"\\n‚úÖ Sentinel installed!\")\n",
    "\n",
    "# Verify installation\n",
    "import sentinel\n",
    "print(f\"Sentinel version: {sentinel.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ImageNet-C (Subset)\n",
    "\n",
    "We'll download just a few corruption types for quick testing.\n",
    "\n",
    "**Option 1:** Download mini subset (recommended for testing)\n",
    "**Option 2:** Download full ImageNet-C (~6GB) - use Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Download mini subset from Kaggle (faster)\n",
    "# You'll need to upload your kaggle.json to Colab\n",
    "\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Upload kaggle.json\n",
    "print(\"Upload your kaggle.json file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Setup Kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download ImageNet-C\n",
    "!kaggle datasets download -d sayakpaul/imagenet-c\n",
    "!unzip -q imagenet-c.zip -d imagenet_c\n",
    "\n",
    "print(\"\\n‚úÖ ImageNet-C downloaded!\")\n",
    "!ls imagenet_c/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Use Google Drive\n",
    "\n",
    "If you already have ImageNet-C in your Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if using Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# \n",
    "# imagenet_c_path = \"/content/drive/MyDrive/imagenet-c\"\n",
    "# imagenet_val_path = \"/content/drive/MyDrive/imagenet/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Test: 3 Corruption Types\n",
    "\n",
    "Let's start with 3 corruption types for a quick benchmark (~15 mins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "imagenet_c_path = \"./imagenet_c\"  # Adjust if needed\n",
    "imagenet_val_path = \"./imagenet_val\"  # You'll need clean ImageNet val set\n",
    "\n",
    "# For quick testing, we'll use synthetic clean images\n",
    "# In production, use real ImageNet validation set\n",
    "\n",
    "corruption_types = [\n",
    "    \"gaussian_noise\",\n",
    "    \"defocus_blur\",\n",
    "    \"motion_blur\",\n",
    "]\n",
    "\n",
    "print(\"Testing on 3 corruption types:\")\n",
    "for c in corruption_types:\n",
    "    print(f\"  - {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./colab')\n",
    "\n",
    "from phase2_benchmark import run_benchmark\n",
    "\n",
    "# Run benchmark\n",
    "results = run_benchmark(\n",
    "    imagenet_c_path=imagenet_c_path,\n",
    "    imagenet_val_path=imagenet_val_path,\n",
    "    corruption_types=corruption_types,\n",
    "    severity=3,  # Medium severity\n",
    "    max_samples_per_corruption=500,  # 500 samples per corruption\n",
    "    max_clean_samples=500,  # 500 clean samples\n",
    "    output_path=\"benchmark_results.json\",\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Benchmark complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load results\n",
    "with open(\"benchmark_results.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Extract data\n",
    "corruptions = [r[\"corruption\"] for r in results[\"corruption_results\"]]\n",
    "sentinel_auroc = [r[\"sentinel_auroc\"] for r in results[\"corruption_results\"]]\n",
    "opencv_blur_auroc = [r[\"opencv_blur_auroc\"] for r in results[\"corruption_results\"]]\n",
    "opencv_hist_auroc = [r[\"opencv_histogram_auroc\"] for r in results[\"corruption_results\"]]\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(corruptions))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, sentinel_auroc, width, label='Sentinel', color='#2ecc71')\n",
    "ax.bar(x, opencv_blur_auroc, width, label='OpenCV Blur', color='#e74c3c')\n",
    "ax.bar(x + width, opencv_hist_auroc, width, label='OpenCV Histogram', color='#95a5a6')\n",
    "\n",
    "ax.set_xlabel('Corruption Type', fontsize=12)\n",
    "ax.set_ylabel('AUROC', fontsize=12)\n",
    "ax.set_title('Sentinel vs OpenCV Baselines on ImageNet-C', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(corruptions, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('benchmark_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Results visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BENCHMARK SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = results[\"summary\"]\n",
    "\n",
    "print(f\"\\nMean AUROC:\")\n",
    "print(f\"  Sentinel:        {summary['sentinel_mean_auroc']:.4f}\")\n",
    "print(f\"  OpenCV Blur:     {summary['opencv_blur_mean_auroc']:.4f}\")\n",
    "print(f\"  OpenCV Histogram: {summary['opencv_hist_mean_auroc']:.4f}\")\n",
    "\n",
    "improvement_blur = (summary['sentinel_mean_auroc'] - summary['opencv_blur_mean_auroc']) * 100\n",
    "improvement_hist = (summary['sentinel_mean_auroc'] - summary['opencv_hist_mean_auroc']) * 100\n",
    "\n",
    "print(f\"\\nImprovement:\")\n",
    "print(f\"  vs OpenCV Blur:  {improvement_blur:+.1f}%\")\n",
    "print(f\"  vs OpenCV Hist:  {improvement_hist:+.1f}%\")\n",
    "\n",
    "# Check if target met\n",
    "target_improvement = 10.0  # 10% improvement target\n",
    "\n",
    "if improvement_blur >= target_improvement:\n",
    "    print(f\"\\n‚úÖ SUCCESS: Beat OpenCV by {improvement_blur:.1f}% (target: {target_improvement}%)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Improvement: {improvement_blur:.1f}% (target: {target_improvement}%)\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Corruption Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame for nice display\n",
    "df_results = []\n",
    "for r in results[\"corruption_results\"]:\n",
    "    df_results.append({\n",
    "        \"Corruption\": r[\"corruption\"],\n",
    "        \"Sentinel AUROC\": f\"{r['sentinel_auroc']:.4f}\",\n",
    "        \"Sentinel F1\": f\"{r['sentinel_f1']:.4f}\",\n",
    "        \"OpenCV Blur AUROC\": f\"{r['opencv_blur_auroc']:.4f}\",\n",
    "        \"OpenCV Hist AUROC\": f\"{r['opencv_histogram_auroc']:.4f}\",\n",
    "        \"Samples\": r[\"num_samples\"],\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(df_results)\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results\n",
    "\n",
    "Download the results JSON and comparison plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download results\n",
    "files.download('benchmark_results.json')\n",
    "files.download('benchmark_comparison.png')\n",
    "\n",
    "print(\"\\n‚úÖ Results downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Full Benchmark (Optional)\n",
    "\n",
    "Run on all 15 ImageNet-C corruption types (takes ~2 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run full benchmark\n",
    "# all_corruptions = [\n",
    "#     \"gaussian_noise\", \"shot_noise\", \"impulse_noise\",\n",
    "#     \"defocus_blur\", \"glass_blur\", \"motion_blur\", \"zoom_blur\",\n",
    "#     \"snow\", \"frost\", \"fog\", \"brightness\",\n",
    "#     \"contrast\", \"elastic_transform\", \"pixelate\", \"jpeg_compression\"\n",
    "# ]\n",
    "# \n",
    "# full_results = run_benchmark(\n",
    "#     imagenet_c_path=imagenet_c_path,\n",
    "#     imagenet_val_path=imagenet_val_path,\n",
    "#     corruption_types=all_corruptions,\n",
    "#     severity=3,\n",
    "#     max_samples_per_corruption=1000,\n",
    "#     max_clean_samples=1000,\n",
    "#     output_path=\"full_benchmark_results.json\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
